2024-04-09

최종 목표
Distributed LLaMa PC(x86)/라즈베리파이 통해서 실행 후 해당 기술의 장점 / 개선할 점 찾기

현재 생각하는 장점 및 단점
장점
1) 유지해주는 사용자가 있다면, 고성능 컴퓨터가 아니더라도 사용하기 용이

단점
1) 분산 시스템인 만큼, 유지를 해주는 사용자들이 없다면 사용에 불편을 겪기 쉬움. 


중간 목표 (4월목표)
PC환경에서의 Distributed LLaMa 실행/파인튜닝 및 기존의 LLaMa/ Chat-GPT와의 성능 비교
라즈베리 파이에서 Distributed LLaMa 실행

주간 목표 (4/15-4/19)
PC환경에서의 Distributed LLaMa 실행-Fine-Tuning
x86환경에서도 Distributed LLaMa 실행및 LLaMa와 Petals 간의 성능 지표 차이 분석
Fine-Tuning후의 성능 지표 차이 분석

다음 주 목표(4/22-4/26)
PC에서의 Petals와 LLaMa2, Chat-GPT와의 차이 분석후 시각화
Petals 만이 아닌 Distributed LLaMa에 대해서 동일한 과정 진행 및 Raspberry Pi에서 Distributed LLaMa 구동과정 진행

진행 상황
4/9(화)
-BK21 서류 작성 마무리
-Colab 환경에서 생성된 Petals 실행

4/11(목)
-BK 서류 작업 수정사항 수정

4/12(금)
- CUDA 재설치 ( 월요일날 CUDA 재설치를 하였으나, conda 가상환경내에서 설치하여 제대로 적용되지 않아 다시 재설치)
- Windows 환경에서 실행하기 위하여 WSL 설치 및 Petals 설치

4/15(월)
- Fine-Tuning을 위한 코드 작성 및 기존 코드 수정
- Fine-Tuning을 위한 Dataset 선택 (일단 기존의 Dataset 사용할 예정)

4/16(화)
-Compare.txt 파일 추가후, Chat-GPT3.5/4 , LLaMa 7B/13B, Petals 를 통해 6개의 질문들을 각각 질문후 질문 내용 및 응답 시간 측정.
비교 결과
1. 응답 품질 및 상세 내용
ChatGPT-3.5: 간결한 응답을 하였으나, ChatGPT-4와 LLaMa에 비해 상세하지 않음.
ChatGPT-4 : 자세하고, 포괄적인 내용들을 담음.
LLaMa-7B: 상세한 내용을 담고, GPT-4보단 부족하지만 기술적인 설명이 뛰어나며, 포괄적인 답변을 제공.
LLaMA-13B : 7B와 유사하지만, 복잡한 주제에 대한 처리능력이 더욱 향상됨.
Petals: 간결한 응답을 하였으며, 다른 모델들에 비해 상세하지않은 응답 제공.
2.정확도
모든 모델들이 기본적으로 정확한 정보를 제공함. 더 심화된 질문통해 정확도 판별 해야할듯.

3. 속도
ChatGPT(3.5/4)는 매우 빠른 속도를 보여주었음.
LLaMa(7B/13B) 모델들은 전반적으로 긴 속도를 보여주었음.
Petals는 LLaMa모델보다는 빠르지만, ChatGPT 모델보다는 느린 속도를 보여주었음.

4. 개선방안
4-1) Petals의 전문성 향상
Petals는 효율적이며, LLaMa보다 신속한 응답 생성 속도를 보여주고있음.
응답품질에 있어서 더 상세한 응답을 제공할 필요성이 있음.
Fine-Tuning을 통해 특정 분야에 대한 전문성을 강화하여, 더 상세한 답변을 할 수 있게 하는 방안 존재.
4-2) 응답속도 향상
현재의 응답속도가 LLaMa에 비해서는 빠르나, ChatGPT에 비해서는 많이 느리므로, 응답속도 향상또한 개선방안이 될 수 있음.



reference list
1.Petals
https://petals.dev/
https://arxiv.org/pdf/2209.01188.pdf
https://github.com/bigscience-workshop/petals?tab=readme-ov-file

2.Distributed LLaMa with Raspberry Pi
https://raw.githubusercontent.com/b4rtaz/distributed-llama/main/report/report.pdf
https://github.com/b4rtaz/distributed-llama

목표(최종, 중간, 주간)와 이에 따른 연구(조사, 아이디어, 정리, 구현, 실험 등등)내용 정리, 
관련 논문/자료 링크 항상 추가 및 reference list 유지
